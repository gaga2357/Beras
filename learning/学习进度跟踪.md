# 学习进度跟踪表

记录你的学习进度，完成后打勾 ✅

## 阶段 0：必备知识准备
- [ ] 复习线性代数（向量、矩阵、矩阵乘法）
- [ ] 复习微积分（导数、链式法则、梯度）
- [ ] 学习 NumPy 基础操作
- [ ] 理解神经网络基本概念

**学习时间：** _____ 小时
**遇到的问题：**
```
(在这里记录问题)
```

---

## 阶段 1：计算图与自动微分
- [ ] 理解计算图的概念
- [ ] 实现 Tensor 类基本结构
- [ ] 实现加法、乘法运算及梯度
- [ ] 实现矩阵乘法及梯度
- [ ] 实现 backward() 方法
- [ ] 通过所有测试

**学习时间：** _____ 小时
**关键收获：**
```
(记录你的理解)
```

**遇到的困难：**
```
(记录困难和解决方案)
```

---

## 阶段 2：激活函数
- [ ] 理解激活函数的作用
- [ ] 实现 ReLU 及其导数
- [ ] 实现 Sigmoid 及其导数
- [ ] 实现 Softmax 及其导数
- [ ] 处理数值稳定性问题
- [ ] 通过梯度检查

**学习时间：** _____ 小时
**关键收获：**
```
(记录你的理解)
```

---

## 阶段 3：神经网络层
- [ ] 理解全连接层的原理
- [ ] 实现 Dense 层前向传播
- [ ] 实现 Dense 层反向传播
- [ ] 实现权重初始化
- [ ] 封装激活层
- [ ] 测试多层网络

**学习时间：** _____ 小时
**关键收获：**
```
(记录你的理解)
```

---

## 阶段 4：损失函数
- [ ] 理解损失函数的作用
- [ ] 实现 MSE 损失
- [ ] 实现 CrossEntropy 损失
- [ ] 处理数值稳定性
- [ ] 通过测试

**学习时间：** _____ 小时

---

## 阶段 5：优化器
- [ ] 理解梯度下降原理
- [ ] 实现 SGD
- [ ] 实现带 Momentum 的 SGD
- [ ] 实现 Adam 优化器
- [ ] 理解各优化器的区别

**学习时间：** _____ 小时

---

## 阶段 6：模型封装
- [ ] 实现 Sequential 模型
- [ ] 实现 compile 方法
- [ ] 实现 fit 训练流程
- [ ] 实现 predict 和 evaluate
- [ ] 实现 summary

**学习时间：** _____ 小时

---

## 阶段 7：数据预处理
- [ ] 实现数据归一化
- [ ] 实现 one-hot 编码
- [ ] 实现批数据生成器
- [ ] 实现数据集分割

**学习时间：** _____ 小时

---

## 阶段 8：综合实战
- [ ] 加载 MNIST 数据
- [ ] 构建 MLP 模型
- [ ] 训练模型
- [ ] 评估性能（目标 >95%）
- [ ] 调试和优化

**最终测试准确率：** _____%
**学习时间：** _____ 小时

---

## 总结与反思

### 最大的收获
```
(写下你学到的最重要的东西)
```

### 还不够理解的地方
```
(记录需要进一步学习的内容)
```

### 下一步计划
```
(你想继续学习什么？)
```

---

**总学习时间：** _____ 小时
**完成日期：** ________
